#!/usr/bin/env python3
"""
è¿è¡Œå›¾åƒæ¨ç†æµ‹è¯• - åªæµ‹è¯•FLUXå’ŒLUMINA
"""

import os
import sys
from pathlib import Path

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).resolve().parent))

from inference_benchmark import InferenceBenchmark

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åº“"""
    # å®šä¹‰åŒ…åå’Œå¯¼å…¥åçš„æ˜ å°„
    packages = {
        'torch': 'torch',
        'diffusers': 'diffusers',
        'transformers': 'transformers',
        'accelerate': 'accelerate',
        'safetensors': 'safetensors',
        'pillow': 'PIL',
        'numpy': 'numpy',
        'psutil': 'psutil',
        'matplotlib': 'matplotlib',
        'seaborn': 'seaborn'
    }
    
    missing_packages = []
    
    for package_name, import_name in packages.items():
        try:
            __import__(import_name)
        except ImportError:
            missing_packages.append(package_name)
    
    if missing_packages:
        print(f"ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åº“: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print("python install_dependencies.py")
        return False
    
    return True

def check_models():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    models = {
        "FLUX": Path("./FLUX.1-dev"),
        "Lumina": Path("./Lumina-Image-2.0")
    }
    
    print("æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§...")
    print("=" * 40)
    
    all_ok = True
    for model_name, model_path in models.items():
        if model_path.exists():
            # æ£€æŸ¥å…³é”®æ–‡ä»¶
            key_files = ["model_index.json"]
            missing_files = []
            
            for file_name in key_files:
                file_path = model_path / file_name
                if not file_path.exists():
                    missing_files.append(file_name)
            
            if missing_files:
                print(f"âŒ {model_name}: ç¼ºå°‘æ–‡ä»¶ {missing_files}")
                all_ok = False
            else:
                print(f"âœ… {model_name}: æ–‡ä»¶å®Œæ•´")
        else:
            print(f"âŒ {model_name}: ç›®å½•ä¸å­˜åœ¨")
            all_ok = False
    
    if not all_ok:
        print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸‹è½½æ¨¡å‹:")
        print("python download_models.py")
        return False
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("FLUXå’ŒLUMINAå›¾åƒæ¨ç†æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return
    
    # æ£€æŸ¥æ¨¡å‹
    if not check_models():
        return
    
    print("\nå¼€å§‹æ¨ç†æµ‹è¯•...")
    
    # åˆ›å»ºæ¨ç†åŸºå‡†æµ‹è¯•å™¨
    benchmark = InferenceBenchmark()
    
    # è¿è¡Œæµ‹è¯•
    results = benchmark.run_all_benchmarks()
    
    if results:
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼Œå…±ç”Ÿæˆ {len(results)} ä¸ªç»“æœ")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡å’ŒæŠ¥å‘Š:")
        print("   - å›¾ç‰‡ç›®å½•: unified_output_*/")
        print("   - æŠ¥å‘Šæ–‡ä»¶: benchmark_report_*/")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥")

if __name__ == "__main__":
    main()
