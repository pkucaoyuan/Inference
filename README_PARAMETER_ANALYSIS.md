# 模型参数量分析工具包

## 概述
这是一个专门用于分析FLUX和LUMINA模型各类型层参数量的工具包，帮助理解模型架构和计算复杂度。

## 工具列表

### 1. 主要分析工具
- **`model_parameter_analysis.py`** - 完整版分析工具，支持命令行参数
- **`quick_parameter_analysis.py`** - 快速分析工具，一键运行
- **`test_parameter_analysis.py`** - 本地模型测试工具

### 2. 辅助工具
- **`run_parameter_analysis.py`** - 启动脚本，提供菜单选择界面
- **`USAGE_GUIDE.md`** - 详细使用说明
- **`PARAMETER_ANALYSIS_README.md`** - 技术文档

## 快速开始

### 方法1: 使用启动脚本（推荐）
```bash
python run_parameter_analysis.py
```
然后选择相应的选项即可。

### 方法2: 直接运行快速分析
```bash
python quick_parameter_analysis.py
```

### 方法3: 使用完整分析工具
```bash
# 分析所有模型
python model_parameter_analysis.py

# 仅分析FLUX
python model_parameter_analysis.py --flux-only

# 仅分析LUMINA
python model_parameter_analysis.py --lumina-only
```

## 功能特点

### 1. 层类型分类
- **Attention层**: 注意力机制相关层
- **线性/卷积层**: 全连接层和卷积层
- **归一化层**: LayerNorm, BatchNorm等
- **激活函数**: ReLU, GELU, SiLU等
- **嵌入层**: 词嵌入和位置嵌入
- **位置编码**: 位置信息编码
- **时间步编码**: 时间步信息编码
- **前馈网络**: MLP和FFN层
- **Transformer块**: 完整的Transformer块
- **残差连接**: 残差网络连接
- **VAE层**: 变分自编码器相关层
- **文本编码器**: 文本编码相关层
- **其他层**: 未分类的层

### 2. 分析内容
- **组件级分析**: Text Encoder, Transformer, VAE参数量
- **层类型分析**: 各类型层参数量统计
- **模型对比**: FLUX vs LUMINA参数量对比
- **内存统计**: 各层内存占用分析

### 3. 输出格式
- **控制台输出**: 实时显示分析进度和结果
- **JSON报告**: 详细的数据报告，便于进一步分析
- **对比表格**: 直观的模型对比结果

## 系统要求

### 硬件要求
- **GPU**: 建议16GB+显存
- **内存**: 建议32GB+系统内存
- **存储**: 至少50GB可用空间

### 软件要求
- **Python**: 3.8+
- **PyTorch**: 2.0+
- **CUDA**: 11.8+ (如果使用GPU)

### 依赖包
```bash
pip install torch torchvision diffusers transformers accelerate
```

## 使用场景

### 1. 模型研究
- 理解模型架构
- 分析计算复杂度
- 比较不同模型

### 2. 性能优化
- 识别参数量大的层
- 优化内存使用
- 模型压缩参考

### 3. 学术研究
- 模型分析论文
- 性能对比研究
- 架构设计参考

## 故障排除

### 常见问题
1. **内存不足**: 使用CPU模式或减少批处理大小
2. **模型加载失败**: 检查网络连接和存储空间
3. **设备映射错误**: 脚本已修复，使用`device_map="balanced"`
4. **依赖包缺失**: 安装所需的Python包

### 解决方案
- 查看`USAGE_GUIDE.md`获取详细说明
- 使用本地模型测试工具
- 检查系统资源使用情况
- 更新到最新版本的依赖包

## 输出示例

```
=== 模型参数量对比 ===
组件                 FLUX参数        LUMINA参数      差异            
----------------------------------------------------------------------
Text Encoder         2,616,479,141   2,616,479,141   0
Transformer          2,609,792,840   2,609,792,840   0
VAE                  167,652,194     167,652,194     0
总计                 5,393,924,175   5,393,924,175   0

=== 各层类型参数量对比 ===
--- FLUX 各层类型统计 ---
层类型               参数数量         层数      大小(MB)    
------------------------------------------------------------
线性/卷积层           4,234,567,890   1,234     8,123.45
Attention层           1,234,567,890   456       2,345.67
前馈网络             890,123,456     234       1,678.90
...
```

## 更新日志

- **v1.0**: 初始版本，支持基本参数量分析
- **v1.1**: 修复设备映射问题
- **v1.2**: 添加本地模型测试功能
- **v1.3**: 优化层类型分类和输出格式
- **v1.4**: 添加启动脚本和菜单界面

## 贡献

欢迎提交Issue和Pull Request来改进这个工具包！

## 许可证

MIT License
